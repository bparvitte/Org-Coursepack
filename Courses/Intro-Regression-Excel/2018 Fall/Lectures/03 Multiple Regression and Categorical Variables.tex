% Intended LaTeX compiler: pdflatex
\documentclass[10pt,article]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{titling} \posttitle{\par\end{center}} \setlength{\droptitle}{-30pt} \usepackage{multicol} \setlength{\columnsep}{1cm} \usepackage[T1]{fontenc} \usepackage[utf8]{inputenc} \renewcommand{\contentsname}{Table of Contents / Agenda} \usepackage[letterpaper,left=1in,right=1in,top=0.7in,bottom=1in,headheight=23pt,includehead,includefoot,heightrounded]{geometry} \usepackage{fancyhdr} \pagestyle{fancy} \fancyhf{} \cfoot{\thepage} \usepackage{mathpazo} \usepackage[scaled=0.85]{helvet} \usepackage{courier} \usepackage[onehalfspacing]{setspace} \usepackage[framemethod=default]{mdframed} \usepackage{wrapfig} \usepackage{booktabs} \usepackage[outputdir=Lectures]{minted}
\setcounter{secnumdepth}{3}
\date{\vspace{-6ex}}
\title{Class 3: Multiple Regression and Categorical Variables}
\hypersetup{
 pdfauthor={},
 pdftitle={Class 3: Multiple Regression and Categorical Variables},
 pdfkeywords={},
 pdfsubject={Description School specific teaching materials},
 pdfcreator={Emacs 26.1 (Org mode 9.1.13)}, 
 pdflang={English}}
\begin{document}

\maketitle
\lhead{ COURSE 0000 \\ Joon H. Ro } 
\rhead{ Class 3 \\ 2018-09-04 Tue} 
\thispagestyle{fancy}

\setcounter{tocdepth}{1}
\tableofcontents
\vspace{6ex}

\section{Categorical Variables}
\label{sec:org462ece1}
\subsection{Use of Dummy Variables}
\label{sec:org05b582a}
\begin{itemize}
\item To capture the effect of categorical variables
\begin{itemize}
\item Brands, In-store displays, Gender
\end{itemize}

\item Dummy variable has a value of 0 or 1
\begin{itemize}
\item 1 indicates presence of characteristic
\item 0 indicates absence of characteristic
\end{itemize}
\end{itemize}
\subsection{Example}
\label{sec:org8d318d4}

{\small
\begin{center}
\begin{tabular}{rl}
Sales & Store Type\\
\hline
10 & A\\
4 & B\\
8 & A\\
6 & B\\
7 & A\\
6 & B\\
7 & B\\
8 & A\\
\end{tabular}
\end{center}
}

\begin{itemize}
\item Categorical variables require recoding
\item Use indicator variables / dummy variables
\end{itemize}

{\small
\begin{center}
\begin{tabular}{rlr}
Sales & Store Type & Dummy\\
\hline
10 & A & 1\\
4 & B & 0\\
8 & A & 1\\
6 & B & 0\\
7 & A & 1\\
6 & B & 0\\
7 & B & 0\\
8 & A & 1\\
\end{tabular}
\end{center}
}
\begin{itemize}
\item Sales Estimate = 5.75 + 2.5 \texttimes{} (if store type is A).
\item Note that this gives a  {\bf relative} measure.
\item Store type A sales are estimated to be 2.5 units  {\bf more than} store type B.
\end{itemize}
\subsection{Coding Dummy Variables}
\label{sec:org65a1c06}
\begin{itemize}
\item If a category can either be present or absent, then code:
\begin{itemize}
\item Presence as 1
\item Absence as 0
\item Example: Presence of "In Store Display"
\end{itemize}
\item If a category can be of two types:
\begin{itemize}
\item Code one of the category as 1
\item Code the other as 0
\item Example: Male/ Female; Cash/ Credit
\end{itemize}
\end{itemize}
\subsection{Coding Dummy Variables: An Example}
\label{sec:org3673571}
\begin{itemize}
\item Do male teachers get more wage in general?
\item Are Texas drivers more likely to buy a pickup truck compared to drivers in
other states?
\end{itemize}
\subsubsection{Model:}
\label{sec:orgdb1c61e}
\begin{itemize}
\item Let \(D_i\) be the dummy variable. Then, when it is true (\(D_{i} =1\)), the model is:

\begin{align*} 
     y_i  & = \beta_0 + \beta_1 x_{1i} + \beta_2 D_i \\
          & = \underbrace{(\beta_0 + \beta_2)}_{\text{intercept}} + \beta_1 x_{1i} 
\end{align*}
\end{itemize}

\begin{itemize}
\item When it is not true (\(D_i = 0\)), the model is:

\begin{align*} 
    y_i & = \beta_0 + \beta_1 x_{1i} + \beta_2 D_i \\
        & = \beta_0 + \beta_1 x_{1i}
\end{align*}
\end{itemize}

\begin{itemize}
\item So \(\beta_2\) represents the relative difference between the two groups
in terms of their intercepts

\item What does it mean when \(\beta_2\) is not significant?
\end{itemize}

\subsection{Dummy coding with more than 2 categories (\(L\) levels)}
\label{sec:org37eafcd}
\begin{multicols}{2}
\begin{itemize}
\item At the most, \(L-1\) variables are needed
\item Choose a base (comparison) variable
\item Code each variable as being the category or not \ldots{}
\end{itemize}

{\small
\begin{center}
\begin{tabular}{rrll}
Sales & REGION & R2ornot & R3ornot\\
\hline
10 & 1 &  0 &  0\\
4 & 2 &  1 &  0\\
8 & 1 &  0 &  0\\
6 & 2 &  1 &  0\\
7 & 3 &  0 &  1\\
6 & 3 &  0 &  1\\
7 & 3 &  0 &  1\\
8 & 1 &  0 &  0\\
\end{tabular}
\end{center}
}

\end{multicols}
\subsection{Dummy Coding for Multi-Category}
\label{sec:org213c770}
what if we have more than one category?

e.g., color = \{ {\bf red},  {\bf green},
 {\bf blue}\} is independent variable (\(x\)) and preference is
dependent variable (\(y\))

use a separate dummy variable for each category, except one (e.g., the last)

\begin{center}
\begin{tabular}{ll}
color is  {\bf red} : & \(D_{i1} = 1, D_{i2} = 0\)\\
color is  {\bf green} : & \(D_{i1} = 0, D_{i2} = 1\)\\
color is  {\bf blue} : & \(D_{i1} = 0, D_{i2} = 0\)\\
\end{tabular}
\end{center}

\[ y_i = \beta_0 + \beta_1 D_{i1} + \beta_2 D_{i2} = 
   \begin{cases} 
   \beta_0 + \beta_1 & \text{if red} \\
   \beta_0 + \beta_2 & \text{if green} \\
   \beta_0  & \text{if blue} \\
  \end{cases} \]

\subsubsection{Interpretation}
\label{sec:org38c719c}

\[ y_i = \beta_0 + \beta_1 D_{i1} + \beta_2 D_{i2} = 
   \begin{cases} 
   \beta_0 + \beta_1 & \text{if red} \\
   \beta_0 + \beta_2 & \text{if green} \\
   \beta_0  & \text{if blue} \\
  \end{cases} \]
\begin{itemize}
\item \(\beta_0\) preference of product if  {\bf blue} (blue is called the \texttt{baseline level})
\item \(\beta_1\) preference of product if  {\bf red} as  {\bf compared to blue} product:
"how much better (worse) is red product liked over blue"
\item \(\beta_2\) preference of product if  {\bf green} as  {\bf compared to blue} product:
"how much better (worse) is green product liked over blue"
\end{itemize}

\subsection{Another Example}
\label{sec:orgfcdc2a0}
\begin{itemize}
\item Brands \texttt{\{ =Sony}, \texttt{Samsung}, \texttt{Bose}\}

\item Use a separate dummy variable for each brand, except one (e.g. the last one)
\begin{itemize}
\item \(D_{Sony}\), \(D_{Samsung}\)
\end{itemize}
\end{itemize}

\begin{itemize}
\item Dummy Coded Variables

\begin{center}
\begin{tabular}{lrrr}
Brand & Brand Code & \(D_{Sony}\) & \(D_{Samsung}\)\\
\hline
Sony & 1 & 1 & 0\\
Samsung & 2 & 0 & 1\\
Bose & 3 & 0 & 0\\
\end{tabular}
\end{center}

\item What is the baseline in this example?
\end{itemize}

\begin{itemize}
\item Letâ€™s say we have the following model to predict sales:
\end{itemize}

\[  Sales = \beta_0 + \beta_1 \times Price + \beta_2 \times Ad + \beta_3 \times
D_{Sony}  + \beta_4 \times D_{Samsung} \]


\begin{itemize}
\item Then, sales for each brand is:
\end{itemize}

\begin{itemize}
\item \(Sales_{Sony} = \beta_0 + \beta_1 \times Price_{Sony} + \beta_2 \times Ad_{Sony} + \beta_3\)
\item \(Sales_{Samsung} = \beta_0 + \beta_1 \times Price_{Samsung} + \beta_2 \times Ad_{Samsung} + \beta_4\)
\item \(Sales_{Bose} = \beta_0 + \beta_1 \times Price_{Bose} + \beta_2 \times Ad_{Bose}\)
\end{itemize}
\section{Multicollinearity}
\label{sec:org7d55df3}
\begin{itemize}
\item Why do we use \(L-1\) variables instead of \(L\) in dummy coding?

\item If you do, you will get \textbf{perfect multicollinearity}

\item What is multicollinearity?
\end{itemize}

\subsection{Multicollinearity}
\label{sec:org24e9259}

\begin{itemize}
\item Source: Two or more independent (\(x_k\)) variables in a multiple
regression model are highly correlated

\item Since two \(x_k\)'s are moving together, it is hard to identify
which one is causing the changes in \(y\)
\end{itemize}

\subsection{Consequences of Multicollinearity}
\label{sec:org861e13f}
\begin{itemize}
\item Estimates of the effect (coefficients) are less precise
\item Small \texttt{t-stat} (= large \texttt{p-value})
\item \texttt{Type 2 Error}: you do not reject the null (\(H_0: \beta=0\)) when you
should
\item But does \textbf{not} actually bias results
\end{itemize}
\subsection{Fixes}
\label{sec:org9179bd5}
\begin{itemize}
\item This is a data problem. If you have sufficient number of observations, high
correlation between explanatory (predictor) variables is okay

\begin{itemize}
\item Standard Errors for estimates become smaller as you increase number of
sample
\end{itemize}
\end{itemize}
\subsection{Perfect multicollinearity}
\label{sec:orgb2bfa19}
\begin{itemize}
\item You have complete dependency among variables (predict one with others)
\item Inversion in OLS estimate formula does not work and you cannot estimate the
model
\item Just like \(1/0\) does not work
\item Not a big problem - you will see the error right away
\end{itemize}
\subsubsection{Dummy Variable Trap}
\label{sec:org83f29ee}
\begin{itemize}
\item If you have \(L\) dummies for \(L\) number of categories, including
a constant term in the regression together guarantee perfect
multicollinearity

\item Analogous to this is that when you know the mean first \(n-1\) observations then
you can infer \(n\)'th observation
\end{itemize}
\section{Making Predictions in Regression Models}
\label{sec:orgb59b576}
Once you have regression results (estimated coefficients,
\(\widehat\beta_k\)'s), it is easy to make predictions given values of
\(x_k\)'s.

\begin{itemize}
\item Remember we are using the linear model:

\[ y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \varepsilon_i \]

\item For example, estimation results can be:

\[ y_i = \underbrace{10}_{\widehat\beta_0} +
           \underbrace{3}_{\widehat\beta_1} x_{i1} + \underbrace{3}_{\widehat\beta_2} 
  x_{i2} \]
\end{itemize}

\begin{itemize}
\item Once we have \(\widehat\beta_k\)'s, given \(x_k\) values, we can
calculate the \textbf{predicted} value of \(y\), \(\widehat y\) by plugging in
those estimates:

\[ \widehat{y}_i = \widehat\beta_0 + \widehat\beta_1 x_{i1} + \widehat\beta_2
     x_{i2} + \cdots + 0 \]

(Because \(\hat{\varepsilon}_i=E[\varepsilon_i]=0\))
\end{itemize}

\begin{itemize}
\item For example, if your estimation results are:

\[ y_i = 10 + 3 x_{i1} + 3 x_{i2} \]
\end{itemize}

\begin{itemize}
\item The estimate of \(y\) for values of \(x_{1} = 5, x_{2} = 4\) is:

\[ \widehat{y} = 10 + 3 \times \underbrace{5}_{x_{1}} + 3 \times \underbrace{4}_{x_{2}} = 37 \]
\end{itemize}
\end{document}